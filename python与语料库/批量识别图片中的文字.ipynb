{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/NLP/爬虫/results/论文\\图.jpg\n",
      "D:/NLP/爬虫/results/论文\\图.jpg\n",
      "\n",
      "第5章基于神经网络的离合词自动识别\n",
      "sigmoid\n",
      "Predict\n",
      "Attention\n",
      "Attention\n",
      "LSTM\n",
      "CNN\n",
      "CNN\n",
      "CNN\n",
      "CNN\n",
      "CNN\n",
      "图53 CNN+LSTM+ Attention模型图\n",
      "(1)输入层:对于给定的离合词识别语料D,假设其中包含n个句子,每\n",
      "个句子用x表示,则D={x1,x2,Xn},每个句子x由m个词语w构成,则x,=\n",
      "(鸣,w2,…,w),其对应的标签y∈{0,1},其中0表示不包含离合词,1表示包含\n",
      "离合词。由于计算机无法直接识别自然语言,因此需要对离合词文本做数字化处\n",
      "理,将文本转化为数字形式再输入神经网络中,目前常用的方法是将字词句或篇\n",
      "章用向量表示。本文使用 word2vec预训练的词向量,将每个词语映射到其对应\n",
      "的词向量。\n",
      "(2)CNN层:本文利用CNN提取离合词及其上下文的字符特征,卷积窗\n",
      "口大小分别设置为2,34,5,通过提取相邻n个词进行局部特征的提取1,从而捕\n",
      "捉上下文搭配词语的语义信息,对整个句子的语义进行表示。\n",
      "(3)LSTM层:通过对上一层得到的向量表示进行拼接,可以对句子的信\n",
      "息进行更加全面的表示。具体的,本文使用LSTM,加入记忆单元与三个门控单\n",
      "元,对厉史信息进行有效的控制。而不是像RNN一样每次都将前一时刻的隐藏\n",
      "层状态完全洗掉,从而增强了其处理长文本序列的能力,也解决了梯度消失的问\n",
      "题\n",
      "(4) Attention层:通过 Self-Attention可以计算出词语和词语之间的依赖关\n",
      "系及一个句子中间每个不同的词语的重要性\n",
      "D:/NLP/爬虫/results/论文\\致谢.jpg\n",
      "D:/NLP/爬虫/results/论文\\致谢.jpg\n",
      "\n",
      "致谢\n",
      "时光荏苒,岁月如梭。三年的研究生生涯即将告一段落。回顾往昔,入学\n",
      "的点点滴滴都历历在目,此刻心中充满感激和与深深的不舍,感激师长的督促\n",
      "与指导,亲人的支持与鼓励,同学的陪伴与成长。值此毕业之际,我由衷地向\n",
      "你们表达最诚挚的谢意\n",
      "首先感谢我的导师曲维光教授,每当我对未来迷茫的时候,或是在学术实践\n",
      "性中遇到困难的时候,曲老师总是及时出现在我身边,为我指明前进的方向。曲\n",
      "老师学高身正,以自己丰富的学术和生活经验,指导我做科研和为人处事的方法,\n",
      "这必将对我今后的人生产生起到深远的影响。因此,在这里我要衷心的感谢我的\n",
      "导师在我研究生生涯中给予的指导、帮助和照顺。\n",
      "感谢课題组的周俊生老师、顾彦慧老师以及魏庭新老师,自从进入我们这\n",
      "个课题组,三位老师给我提供了很多宝贵的意见和帮助,不断拓展我们的知识\n",
      "面。周老师深厚的理论功底,渊博的学识,认真的工作态度是我学习的榜样\n",
      "顾老师和蔼可亲的待人方式,科学严谨的研究方法都使我受益匪浅。魏老师从\n",
      "研一开始就一直在跟进我的工作进展,不仅在日常学习上给了我很多帮助,还\n",
      "对我毕业论文的撰写提出了很多指导性的意见。\n",
      "感谢实验室的诸位同学,他们每个人都对计算机由衷的热爱,在实验室中\n",
      "创造了良好的学术氛围。平日学习中,每次与他们的交流讨论都让我受益匪\n",
      "浅,往往能让我突破思维桎梏,迈向研究的下一阶段。本论文的研究工作也收\n",
      "到了诸多同学的意见指导,为我提供了许多宝贵的建议。\n",
      "感谢我的父母与亲人,你们的关怀与鼓舞,是我学习工作的动力,你们默\n",
      "默的支持与帮助,是我最为坚强的后盾。\n",
      "最后,对参加论文评审答辩的各位老师表示衷心的感谢!\n",
      "Running time: 5.22 Seconds\n"
     ]
    }
   ],
   "source": [
    "from aip import AipOcr\n",
    "import time\n",
    "import os\n",
    "#获取开始时间\n",
    "start = time.time()\n",
    "\n",
    "\"\"\" 你的 APPID AK SK \"\"\"\n",
    "APP_ID = '18782573'\n",
    "API_KEY = ' 6nYTHKqaLHdnl7GxOTm9sFDl'\n",
    "SECRET_KEY = 'AXNuBRkBhmhZzlxX3Sv8IAdzhlb9RpL1'\n",
    "\n",
    "client = AipOcr(APP_ID, API_KEY, SECRET_KEY)\n",
    "\n",
    "\n",
    "\"\"\" 读取图片 \"\"\"\n",
    "def get_file_content(filePath):\n",
    "    print(filePath)\n",
    "    with open(filePath, 'rb') as fp:\n",
    "        return fp.read()\n",
    "    \n",
    "\"\"\" 写入文本 \"\"\"\n",
    "def write_on_txt(content,filePath,linefeed = \"1\"):\n",
    "    \"\"\"\n",
    "    content：要写入的内容\n",
    "    filePath：要写入文件的路径\n",
    "    linefeed ：判断是否换行\n",
    "        - 1 为不换行 \n",
    "        - 其他 为换行\n",
    "    \"\"\"\n",
    "    #只需要将之前的”w\"改为“a\"即可，代表追加内容\n",
    "    with open(filePath,\"a\") as file:\n",
    "        try:\n",
    "            file.write(content)\n",
    "        except:\n",
    "            print(\"写入错误\")\n",
    "        else:\n",
    "            if linefeed != \"1\":\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "#图片路径\n",
    "img_path = r\"D:/NLP/爬虫/results/论文\" # 也可采用 r\" D:\\Test_path\" 或者是\"D:/Test_path\"\n",
    "#文本路径\n",
    "txt_path = r\"D:/NLP/爬虫/results/论文/图片.txt\"\n",
    "\n",
    "options = {}\n",
    "\n",
    "#遍历所有文件（使用 os.walk 方法）\n",
    "for root,dirs,files in os.walk(img_path):\n",
    "    for file in files:\n",
    "        # 使用join函数将文件名称和文件所在根目录连接起来\n",
    "        file_dir = os.path.join(root, file)\n",
    "        print(file_dir)\n",
    "        write_on_txt(\"=============================\",txt_path,\"0\")\n",
    "        write_on_txt(\"文件名:\"+ file_dir,txt_path,\"0\")\n",
    "        #判断是否是图片\n",
    "        if file_dir[-4:]==\".png\"or file_dir[-4:]==\".jpg\":\n",
    "            #传入图片\n",
    "            image = get_file_content(file_dir)\n",
    "            \"\"\" 调用通用文字识别, 图片参数为本地图片 \"\"\"\n",
    "            a = client.basicGeneral(image, options)\n",
    "            # 查看返回的结果\n",
    "            # print(a['words_result'])\n",
    "            print()\n",
    "            for dic in a['words_result']:\n",
    "                print(dic['words'])\n",
    "                write_on_txt(dic['words'],txt_path,\"0\")\n",
    "                    \n",
    "end = time.time()\n",
    "print('Running time: %1.2f Seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.jianshu.com/p/66c23324a9d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
