{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六章 文本模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本部分主要介绍Python中的文本处理模块：Gensim的使用，并介绍中文分词工具 Jieba。\n",
    "\n",
    "Gensim 是一个免费的文本处理库， 它可以用来从文档中自动提取语义主题。Gensim致力于处理原始的、非结构化的普通文本。Gensim中包含许多先进常用的文本处理算法，如Word2Vec,潜在语义分析（Latent Semantic Analysis，LSA）、隐含狄利克雷分配（Latent Dirichlet Allocation，LDA）等。 Gensim 是一个无监督的学习包，这意味着用户只需准备文本，其他什么信息都用提供。\n",
    "    \n",
    "Gensim工具包主要运行对象是英文的文本，中文文本和英文文本最大的不同是中文需要分词。Jieba是一个功能很强大的分词工具包。本讲将通过有趣的例子讲解如何使用这些工具包。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一节  Gensim 模块简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**安装：**\n",
    "\n",
    "pip install --upgrade gensim\n",
    "\n",
    "or\n",
    "\n",
    "conda install -c conda-forge gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim 的基本特性**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Memory independence – there is no need for the whole training corpus to reside fully in RAM at any one time (can process large, web-scale corpora).\n",
    "- Memory sharing – trained models can be persisted to disk and loaded back via mmap. Multiple processes can share the same data, cutting down RAM footprint.\n",
    "- Efficient implementations for several popular vector space algorithms, including Word2Vec, Doc2Vec, FastText, TF-IDF, Latent Semantic Analysis (LSI, LSA, see LsiModel), Latent Dirichlet Allocation (LDA, see LdaModel) or Random Projection (see RpModel).\n",
    "- I/O wrappers and readers from several popular data formats.\n",
    "- Fast similarity queries for documents in their semantic representation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The principal design objectives behind Gensim are:**\n",
    "- Straightforward interfaces and low API learning curve for developers. Good for prototyping.\n",
    "- Memory independence with respect to the size of the input corpus; all intermediate steps and algorithms operate in a streaming fashion, accessing one document at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一些基本概念**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corpus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些数字文档的集合（A collection of digital documents）。\n",
    "\n",
    "Gensim 中的Corpora有两个主要功能：\n",
    "\n",
    "- 作为输入，训练模型。模型使用这些corpora训练参数。\n",
    "- 整理和管理文档。训练好模型后，模型行可以用来对新的文档抽取信息：如提取topic等。这些新的文档就组成新的coupus。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector space model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 在向量空间中，所有的文档都用向量来表示。这些向量代表一些特征的取值。特征可以看作是一个问题的代表，取值可以看成是该问题的答案。例如：\n",
    " \n",
    "        How many times does the word splonge appear in the document? Zero.\n",
    "        \n",
    "        How many paragraphs does the document consist of? Two.\n",
    "        \n",
    "        How many fonts does the document use? Five.\n",
    "\n",
    "问题通常用id来表示，比如上面三个问题，可以分别用1，2，3来表示。于是，文档就可以用（id，value）数对来表示：(1, 0.0), (2, 2.0), (3, 5.0).\n",
    "\n",
    "\n",
    "如果事先把所有的问题都排列好，就可以用一个向量来表示文档，如上面的例子可以用(0.0, 2.0, 5.0)来表示。\n",
    "\n",
    "通常，一个corpus用很多问题来描述，但是一个文档中的问题很少。所以，要用非常稀疏的向量来表示一个文档，即向量中有很多0。可以使用稀疏矩阵表示方法。\n",
    "\n",
    "如果两个文档对应的向量很接近，通常代表两个文档有“某种”近似性，可以对文档进行聚类和分类。当然，聚类或者分类的效果如何，取决于特征的选取是否有针对性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim sparse vector, Bag-of-words vector**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    在Gensim中，用稀疏向量老表示文档，以节约空间。例如上面的例子可以用向量(0.0, 2.0, 5.0)表示,也可以用[(2, 2.0), (3, 5.0)] 来表示，注意到这种表示方法去掉了(1, 0.0)。这种表示方法对于稀疏向量特别有效。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gensim streamed corpus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Gensim 并不事先指定corpus的格式。 A corpus 就是**稀疏向量**的序列。\n",
    "\n",
    "    例如 [ [(2, 2.0), (3, 5.0)], [(3, 1.0)] ] 是一个含有两个文档的corpus。这是用python list 来表示的。实际上Gensim可以用任何课循环的结构来表示corpus。可以是numpy array，可以是data frame。 只要他能得到一个bag of wrods vector即可。\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model, Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    稀疏向量用来表示文档。多个文档可以用更抽象的参数来表达。所以model本质上是从文本数据到另一种数据（参数）的变换。模型的参数是从训练数据训练出来的。\n",
    "    \n",
    "    Gensim 实现了许多有用的文本处理model，包括 Word2Vec, LsiModel, LdaModel, FastText 等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora and Vector Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从文本到向量空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步：切分词 （tokenize），去stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "     [word for word in document.lower().split() if word not in stoplist]\n",
    "     for document in documents\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二步：对每个词语分别计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'a': 0,\n",
       "             'human': 2,\n",
       "             'machine': 1,\n",
       "             'interface': 2,\n",
       "             'lab': 1,\n",
       "             'abc': 1,\n",
       "             'computer': 2,\n",
       "             'applications': 1,\n",
       "             'survey': 2,\n",
       "             'user': 3,\n",
       "             'opinion': 1,\n",
       "             'system': 4,\n",
       "             'response': 2,\n",
       "             'time': 2,\n",
       "             'eps': 2,\n",
       "             'management': 1,\n",
       "             'engineering': 1,\n",
       "             'testing': 1,\n",
       "             'relation': 1,\n",
       "             'perceived': 1,\n",
       "             'error': 1,\n",
       "             'measurement': 1,\n",
       "             'generation': 1,\n",
       "             'random': 1,\n",
       "             'binary': 1,\n",
       "             'unordered': 1,\n",
       "             'trees': 3,\n",
       "             'intersection': 1,\n",
       "             'graph': 3,\n",
       "             'paths': 1,\n",
       "             'minors': 2,\n",
       "             'iv': 1,\n",
       "             'widths': 1,\n",
       "             'well': 1,\n",
       "             'quasi': 1,\n",
       "             'ordering': 1})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三步：去掉出现次数特别低的词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "     [token for token in text if frequency[token] > 1]\n",
    "     for text in texts\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为将corpus转化成一个向量表示：矩阵。需要构建一个从questions（or words）到id的映射：词典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "#dictionary.save('/tmp/deerwester.dict')  # store the dictionary, for future reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id) ## 给每个单词（token）一个编号（id）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们有一个（新的）文档，使用刚才定义好的词典，可以将之转化为一个向量。\n",
    "\n",
    "两步：\n",
    "1. 切分词 \n",
    "2. 转化（遇到新词忽略）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数（方法）doc2bow()（doc to bag of words）就是用来数一数每个不同单词出现的次数，把单词对应到对应的id，然后返回一个稀疏向量。稀疏向量[(0, 1), (1, 1)] 意味着： 在新的文档“Human computer interaction”中，单词computer (id 0) 和 human (id 1) 出现1次，字典中其他的10个单词出现0次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若将一个corpus 转化成一个稀疏矩阵，只需将corpus里每一个文档单独转成稀疏向量即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当文本比较大的时候，我们不希望将文本一次性都读进内存，而是一次处理一个文档。这时候，用到一种数据结构：**生成器**。下面简单介绍一下生成器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成器非常类似list。不同的是list一次创建所有元素，把所有的空间给开辟出来。而生成器只是告诉元算将按照什么规律放进内存中，不用的时候就不开辟空间。边计算边生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**生成器的创建**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (x*x for x in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x1a19bb98b8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-73ec0726ff88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = [x*x for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对生成器的引用，常用的有两种方法，而第二种方法最常用。注意：generator是一个**可迭代对象**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (x*x for x in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g),next(g),next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "for ele in g:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用函数来定义generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even():\n",
    "    print('step 1')\n",
    "    yield 2\n",
    "    print('step 2')\n",
    "    yield(4)\n",
    "    print('step 3')\n",
    "    yield(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = even()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2\n",
      "4\n",
      "step 3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for e in ev:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(max):\n",
    "    n, a, b = 0, 0, 1\n",
    "    while n < max:\n",
    "        yield b\n",
    "        a, b = b, a + b\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fibs = fib(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "for f in fibs:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 5, 8, 13, 21]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fibs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fibs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到 corpus 的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "     def __iter__(self):\n",
    "         for line in open('mycorpus.txt'):\n",
    "             # assume there's one document per line, tokens separated by whitespace\n",
    "             yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x1a19a04f60>\n"
     ]
    }
   ],
   "source": [
    "corpus_memory_friendly = MyCorpus()  # doesn't load the corpus into memory!\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
      "[(1, 1), (5, 2), (8, 1)]\n",
      "[(3, 1), (6, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(4, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "for vector in corpus_memory_friendly:  # load one vector into memory at a time\n",
    "     print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
      " [(1, 1), (5, 2), (8, 1)],\n",
      " [(3, 1), (6, 1), (7, 1)],\n",
      " [(9, 1)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(corpus_memory_friendly))  # calling list() will convert any sequence to a plain Python list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics and Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们将介绍将文本表达从一种方式（BOW）转换为另一种方式（tf-idf，topics， etc）。\n",
    "\n",
    "转换过程有两个目标：\n",
    "1. 带来文本的隐结构，挖掘单词之间的关系，期望带来语意理解。\n",
    "2. 使文档表达更加紧凑。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变换的基本步骤\n",
    "1. 模型初始化\n",
    "2. 使用模型来转化文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus) ## 初始化，tfidf模型“不需要”training！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bow = [(0, 1), (1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.7071067811865476), (1, 0.7071067811865476)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x1a19ba8828>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
      "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_tfidf:\n",
    "     print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$weight_{i,j} = frequency_{i,j} * \\log_2 \\frac{D}{document\\_freq_{i}}$\n",
    "\n",
    "$weight_{i,j} = wlocal(frequency_{i,j}) * wglobal(document\\_freq_{i}, D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用的transformations(model)\n",
    "- tfidf\n",
    "- lsi\n",
    "- lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.TfidfModel(corpus, normalize=True) ## tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=300) ## lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LdaModel(corpus, id2word=dictionary, num_topics=100) ## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)# initialize an LSI transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lsi = lsi[corpus_tfidf]  # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '0.460*\"system\" + 0.373*\"user\" + 0.332*\"eps\" + 0.328*\"interface\" + 0.320*\"time\" + 0.320*\"response\" + 0.293*\"computer\" + 0.280*\"human\" + 0.171*\"survey\" + -0.161*\"trees\"')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.06600783396090251), (1, 0.5200703306361852)]\n",
      "[(0, 0.19667592859142344), (1, 0.7609563167700055)]\n",
      "[(0, 0.08992639972446315), (1, 0.7241860626752507)]\n",
      "[(0, 0.07585847652178036), (1, 0.632055158600343)]\n",
      "[(0, 0.10150299184980016), (1, 0.5737308483002961)]\n",
      "[(0, 0.7032108939378312), (1, -0.16115180214025707)]\n",
      "[(0, 0.8774787673119833), (1, -0.16758906864659295)]\n",
      "[(0, 0.9098624686818578), (1, -0.14086553628718898)]\n",
      "[(0, 0.6165825350569278), (1, 0.05392907566389456)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_lsi:  # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "     print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -0.617), (1, 0.054)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(0, -0.066), (1, 0.520)] # \"Human machine interface for lab abc computer applications\"\n",
    "[(0, -0.197), (1, 0.761)] # \"A survey of user opinion of computer system response time\"\n",
    "[(0, -0.090), (1, 0.724)] # \"The EPS user interface management system\"\n",
    "[(0, -0.076), (1, 0.632)] # \"System and human system engineering testing of EPS\"\n",
    "[(0, -0.102), (1, 0.574)] # \"Relation of user perceived response time to error measurement\"\n",
    "[(0, -0.703), (1, -0.161)] # \"The generation of random binary unordered trees\"\n",
    "[(0, -0.877), (1, -0.168)] # \"The intersection graph of paths in trees\"\n",
    "[(0, -0.910), (1, -0.141)] # \"Graph minors IV Widths of trees and well quasi ordering\"\n",
    "[(0, -0.617), (1, 0.054)] # \"Graph minors A survey\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:similarity between pairs of documents, or the similarity between a specific document and a set of other documents (such as a user query vs. indexed documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4618210045327159), (1, -0.0700276652789995)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
    "print(vec_lsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])  # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.998093),\n",
      " (1, 0.93748635),\n",
      " (2, 0.9984453),\n",
      " (3, 0.9865886),\n",
      " (4, 0.90755945),\n",
      " (5, -0.12416792),\n",
      " (6, -0.10639259),\n",
      " (7, -0.09879464),\n",
      " (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
    "pprint(list(enumerate(sims))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.9984453), (0, 0.998093), (3, 0.9865886), (1, 0.93748635), (4, 0.90755945), (8, 0.050041765), (7, -0.09879464), (6, -0.10639259), (5, -0.12416792)]\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims)  # print sorted (document number, similarity score) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.99844527),\n",
       " (0, 0.99809301),\n",
       " (3, 0.9865886),\n",
       " (1, 0.93748635),\n",
       " (4, 0.90755945),\n",
       " (8, 0.050041795),\n",
       " (7, -0.098794639),\n",
       " (6, -0.1063926),\n",
       " (5, -0.12416792)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(2, 0.99844527), # The EPS user interface management system\n",
    "(0, 0.99809301), # Human machine interface for lab abc computer applications\n",
    "(3, 0.9865886), # System and human system engineering testing of EPS\n",
    "(1, 0.93748635), # A survey of user opinion of computer system response time\n",
    "(4, 0.90755945), # Relation of user perceived response time to error measurement\n",
    "(8, 0.050041795), # Graph minors A survey\n",
    "(7, -0.098794639), # Graph minors IV Widths of trees and well quasi ordering\n",
    "(6, -0.1063926), # The intersection graph of paths in trees\n",
    "(5, -0.12416792)] # The generation of random binary unordered trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing to note here is that documents no. 2 (\"The EPS user interface management system\") and 4 (\"Relation of user perceived response time to error measurement\") would never be returned by a standard boolean fulltext search, because they do not share any common words with \"Human computer interaction\". However, after applying LSI, we can observe that both of them received quite high similarity scores (no. 2 is actually the most similar!), which corresponds better to our intuition of them sharing a “computer-human” related topic with the query. In fact, this semantic generalization is the reason why we apply transformations and do topic modelling in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 2 LDA topics, using 1 pass and updating once every 1 chunk (10,000 documents)\n",
    "lda = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, update_every=1, passes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.150*\"graph\" + 0.150*\"trees\" + 0.117*\"minors\" + 0.089*\"interface\" + 0.083*\"human\" + 0.074*\"survey\" + 0.071*\"computer\" + 0.064*\"system\" + 0.060*\"user\" + 0.057*\"eps\"'),\n",
       " (1,\n",
       "  '0.170*\"system\" + 0.129*\"user\" + 0.102*\"time\" + 0.095*\"response\" + 0.087*\"eps\" + 0.075*\"computer\" + 0.072*\"survey\" + 0.065*\"human\" + 0.060*\"interface\" + 0.054*\"trees\"')]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.7810477), (1, 0.2189523)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bow = corpus[0]\n",
    "doc_lda = lda[doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.78101426), (1, 0.21898568)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用类似LSI的方式来retrive相似docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(lda[corpus])  # transform corpus to lda space and index it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lda = lda[vec_bow] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.6087217), (1, 0.3912784)]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = index[vec_lda] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95598096, 0.6181355 , 0.66656095, 0.65768224, 0.6668091 ,\n",
       "       0.9775667 , 0.93866295, 0.91477025, 0.9233764 ], dtype=float32)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.95598096),\n",
       " (1, 0.6181355),\n",
       " (2, 0.66656095),\n",
       " (3, 0.65768224),\n",
       " (4, 0.6668091),\n",
       " (5, 0.9775667),\n",
       " (6, 0.93866295),\n",
       " (7, 0.91477025),\n",
       " (8, 0.9233764)]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(sims)) # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.9775667),\n",
       " (0, 0.95598096),\n",
       " (6, 0.93866295),\n",
       " (8, 0.9233764),\n",
       " (7, 0.91477025),\n",
       " (4, 0.6668091),\n",
       " (2, 0.66656095),\n",
       " (3, 0.65768224),\n",
       " (1, 0.6181355)]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(texts, min_count=1,size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.25412136, -0.48533088, 0.96896124]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.wv.similarity(\"graph\", u\"trees\"),model.wv.similarity(\"graph\", u\"computer\"),\n",
    "model.wv.similarity(\"computer\", u\"trees\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21329825, -0.1021911 ], dtype=float32)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.21329825, -0.1021911 ], dtype=float32),\n",
       " array([ 0.0875387 , -0.03911031], dtype=float32),\n",
       " array([0.10965599, 0.17801744], dtype=float32),\n",
       " array([0.22472006, 0.21634078], dtype=float32),\n",
       " array([-0.16486742, -0.02523296], dtype=float32),\n",
       " array([ 0.22886619, -0.00961605], dtype=float32),\n",
       " array([-0.00428852, -0.04174777], dtype=float32),\n",
       " array([-0.0066641 , -0.03673173], dtype=float32),\n",
       " array([0.21474117, 0.1743777 ], dtype=float32),\n",
       " array([ 0.14349584, -0.12003089], dtype=float32),\n",
       " array([-0.1628166 , -0.11556574], dtype=float32),\n",
       " array([-0.19727072,  0.03786341], dtype=float32)]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.wv[wd] for wd in dictionary.id2token.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([model.wv[wd] for wd in dictionary.id2token.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213298</td>\n",
       "      <td>-0.102191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087539</td>\n",
       "      <td>-0.039110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.109656</td>\n",
       "      <td>0.178017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.224720</td>\n",
       "      <td>0.216341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.164867</td>\n",
       "      <td>-0.025233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.228866</td>\n",
       "      <td>-0.009616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.004289</td>\n",
       "      <td>-0.041748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.006664</td>\n",
       "      <td>-0.036732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214741</td>\n",
       "      <td>0.174378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.143496</td>\n",
       "      <td>-0.120031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.162817</td>\n",
       "      <td>-0.115566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.197271</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   0.213298 -0.102191\n",
       "1   0.087539 -0.039110\n",
       "2   0.109656  0.178017\n",
       "3   0.224720  0.216341\n",
       "4  -0.164867 -0.025233\n",
       "5   0.228866 -0.009616\n",
       "6  -0.004289 -0.041748\n",
       "7  -0.006664 -0.036732\n",
       "8   0.214741  0.174378\n",
       "9   0.143496 -0.120031\n",
       "10 -0.162817 -0.115566\n",
       "11 -0.197271  0.037863"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [wd for wd in dictionary.id2token.values()]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df.iloc[:,0],df.iloc[:,1],'.')\n",
    "for i in range(df.shape[0]):\n",
    "    x = df.iloc[i,0]\n",
    "    y = df.iloc[i,1]\n",
    "    text = words[i]\n",
    "    plt.text(x,y,text,fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [wd for wd in dictionary.id2token.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer',\n",
       " 'human',\n",
       " 'interface',\n",
       " 'response',\n",
       " 'survey',\n",
       " 'system',\n",
       " 'time',\n",
       " 'user',\n",
       " 'eps',\n",
       " 'trees',\n",
       " 'graph',\n",
       " 'minors']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information:https://radimrehurek.com/gensim/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三节  Jieba 模块简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jieba 是一款很好用的中文分词包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特点：**\n",
    "\n",
    "    支持三种分词模式：\n",
    "        精确模式，试图将句子最精确地切开，适合文本分析；\n",
    "        全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；\n",
    "        搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。\n",
    "\n",
    "    支持繁体分词\n",
    "\n",
    "    支持自定义词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 来到/ 北京/ 北京大学/ 北京大学光华管理学院/ 大学/ 光华/ 管理/ 管理学/ 理学/ 理学院/ 学院/ / \n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京大学光华管理学院。\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 我/ 来到/ 北京大学光华管理学院\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"我来到北京大学光华管理学院\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他, 来到, 了, 网易, 杭研, 大厦\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**调整词典**\n",
    "\n",
    "- 使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。\n",
    "- 使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n",
    "- 注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(('中', '将'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果/放到/post/中/将/出错/。\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('如果放到post中将出错。', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「/台/中/」/正确/应该/不会/被/切开\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(jieba.cut('「台中」正确应该不会被切开', HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq('台中', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义词/库中/也/增加/了/此/词为/N/类/\n",
      "/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分出/來凱/特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word('石墨烯')\n",
    "jieba.add_word('凱特琳')\n",
    "jieba.del_word('自定义词')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义/词库/中/也/增加/了/此/词为/N/类/\n",
      "/「/台中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "words = jieba.cut(test_sent)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'北京大学光华管理学院, 中, 商业, 分析, 是, 你, 值得, 信赖, 的, 选择'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(jieba.cut(\"北京大学光华管理学院中商业分析是你值得信赖的选择\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word('商业分析')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'北京大学光华管理学院, 中, 商业分析, 是, 你, 值得, 信赖, 的, 选择'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(jieba.cut(\"北京大学光华管理学院中商业分析是你值得信赖的选择\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**作业**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对红楼梦分词\n",
    "2. 研究前80回和后80回虚词分布的异同\n",
    "3. 利用word2vec模型，研究贾宝玉和各人物之间的远近\n",
    "4. 将各人物图画在二维平面坐标中\n",
    "5. 利用topic model，研究前5回的主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
